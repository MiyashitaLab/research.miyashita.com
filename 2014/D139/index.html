<!DOCTYPE html><html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1"><title>自由なテンポで演奏した複数の録音データから楽曲を生成するシステム | Miyashita Lab Research</title><link rel="canonical" href="https://research.miyashita.com/2014/D139/"><meta name="citation_title" content="自由なテンポで演奏した複数の録音データから楽曲を生成するシステム"><meta name="citation_author" content="川名勇気"><meta name="citation_author" content="宮下芳明"><meta name="citation_date" content="2014/03/06"><meta name="citation_year" content="2014"><meta name="citation_publication_date" content="2014/03/06"><meta name="citation_firstpage" content="1"><meta name="citation_lastpage" content="8"><meta name="citation_abstract_html_url" content="https://research.miyashita.com/2014/D139/"><meta name="citation_language" content="ja"><meta name="citation_conference" content="研究報告ヒューマンコンピュータインタラクション（HCI）"><meta name="citation_conference_title" content="研究報告ヒューマンコンピュータインタラクション（HCI）"><meta name="citation_volume" content="2014-HCI-157"><meta name="citation_issue" content="17"><meta name="citation_publisher" content="情報処理学会"><meta name="citation_pdf_url" content="https://research.miyashita.com/2014/D139/D139.pdf"><meta name="description" content="本研究では，1 つの楽曲を制作する際に，各パートの奏者がテンポを自由に演奏した録音データを統合して，合奏を行っているような楽曲を生成できるシステムを提案する．複数の録音データのテンポを同期させるための 「マーク付け」 と，生成する楽曲のテンポとなる 「指揮データ」 を選択することで，他の録音データがこの指揮データに合わせて合奏しているかのような音楽を生成することができる．本システムによって，現在の録音方法で用いられている，ガイドリズムのクリック音や既存の演奏のテンポに合わせて演奏を行うといった方法をとる必要がなくなる．そのため，奏者はテンポに合わせることから解放され，自由に演奏を行うことができるので演奏表現が十分に発揮される．また，楽曲の制作者は，DAW 上での複雑な作業から解放される．これまでは，テンポが既に決まっている楽曲を 1 つしか作ることができなかったが，本システムでは録音データの数だけ指揮データを選ぶことができるため，テンポによって生まれる音楽表現について，楽曲の創造の幅を広げることが可能となっている．"><meta property="og:type" content="article"><meta property="og:title" content="自由なテンポで演奏した複数の録音データから楽曲を生成するシステム"><meta property="og:url" content="https://research.miyashita.com/2014/D139/"><meta property="og:description" content="本研究では，1 つの楽曲を制作する際に，各パートの奏者がテンポを自由に演奏した録音データを統合して，合奏を行っているような楽曲を生成できるシステムを提案する．複数の録音データのテンポを同期させるための 「マーク付け」 と，生成する楽曲のテンポとなる 「指揮データ」 を選択することで，他の録音データがこの指揮データに合わせて合奏しているかのような音楽を生成することができる．本システムによって，現在の録音方法で用いられている，ガイドリズムのクリック音や既存の演奏のテンポに合わせて演奏を行うといった方法をとる必要がなくなる．そのため，奏者はテンポに合わせることから解放され，自由に演奏を行うことができるので演奏表現が十分に発揮される．また，楽曲の制作者は，DAW 上での複雑な作業から解放される．これまでは，テンポが既に決まっている楽曲を 1 つしか作ることができなかったが，本システムでは録音データの数だけ指揮データを選ぶことができるため，テンポによって生まれる音楽表現について，楽曲の創造の幅を広げることが可能となっている．"><meta property="og:image" content="https://research.miyashita.com/2014/D139/thumb.jpg"><meta property="article:author" content="川名勇気, 宮下芳明"><meta name="twitter:card" content="summary_large_image"><meta name="twitter:image" content="https://research.miyashita.com/2014/D139/thumb.jpg"><meta name="twitter:site" content="@Miyashita_Lab"><meta name="twitter:title" content="自由なテンポで演奏した複数の録音データから楽曲を生成するシステム"><meta name="twitter:description" content="本研究では，1 つの楽曲を制作する際に，各パートの奏者がテンポを自由に演奏した録音データを統合して，合奏を行っているような楽曲を生成できるシステムを提案する．複数の録音データのテンポを同期させるための 「マーク付け」 と，生成する楽曲のテンポとなる 「指揮データ」 を選択することで，他の録音データがこの指揮データに合わせて合奏しているかのような音楽を生成することができる．本システムによって，現在の録音方法で用いられている，ガイドリズムのクリック音や既存の演奏のテンポに合わせて演奏を行うといった方法をとる必要がなくなる．そのため，奏者はテンポに合わせることから解放され，自由に演奏を行うことができるので演奏表現が十分に発揮される．また，楽曲の制作者は，DAW 上での複雑な作業から解放される．これまでは，テンポが既に決まっている楽曲を 1 つしか作ることができなかったが，本システムでは録音データの数だけ指揮データを選ぶことができるため，テンポによって生まれる音楽表現について，楽曲の創造の幅を広げることが可能となっている．"><meta name="twitter:label1" content="Book title"><meta name="twitter:data1" content="研究報告ヒューマンコンピュータインタラクション（HCI）"><meta name="twitter:label2" content="Date of issue"><meta name="twitter:data2" content="2014/03/06"><script type="application/ld+json">{"@context":"http://schema.org","@type":"WebSite","name":"自由なテンポで演奏した複数の録音データから楽曲を生成するシステム","url":"https://research.miyashita.com/2014/D139/"}</script><link rel="stylesheet" href="/style/index.css"></head><body><nav class="px2 pt2 pb1 border-bottom clearfix"><div class="left col-12 md-col-2 pb1 center nowrap"><a href="/">Miyashita Lab Research</a></div><div class="right col-12 md-col-3 lg-col-2 pb1"><form class="flex" method="GET" action="/search"><input class="flex-auto px1 border" type="search" name="q" placeholder="Search"></form></div></nav><header class="max-width-4 mx-auto px2"><div class="px2 mb3 border-bottom"><p class="bold"><span>Conference Proceedings</span></p><h1 class="m0 lg-h1 h2 pb1">自由なテンポで演奏した複数の録音データから楽曲を生成するシステム</h1><h3 class="right-align"><span class="nowrap ml2">川名勇気</span><wbr><span class="nowrap ml2">宮下芳明</span><wbr></h3></div></header><section class="max-width-4 mx-auto px2"><div class="lg-px4"><div class="video-wrapper"><iframe class="video-content" src="https://www.youtube.com/embed/tiKt72dF4QE?rel=0" frameborder="0" allowfullscreen></iframe></div></div></section><section class="max-width-4 mx-auto px2"><h2 class="px2 pb1 border-bottom">Abstract</h2><div class="px2 lg-pl4">本研究では，1 つの楽曲を制作する際に，各パートの奏者がテンポを自由に演奏した録音データを統合して，合奏を行っているような楽曲を生成できるシステムを提案する．複数の録音データのテンポを同期させるための 「マーク付け」 と，生成する楽曲のテンポとなる 「指揮データ」 を選択することで，他の録音データがこの指揮データに合わせて合奏しているかのような音楽を生成することができる．本システムによって，現在の録音方法で用いられている，ガイドリズムのクリック音や既存の演奏のテンポに合わせて演奏を行うといった方法をとる必要がなくなる．そのため，奏者はテンポに合わせることから解放され，自由に演奏を行うことができるので演奏表現が十分に発揮される．また，楽曲の制作者は，DAW 上での複雑な作業から解放される．これまでは，テンポが既に決まっている楽曲を 1 つしか作ることができなかったが，本システムでは録音データの数だけ指揮データを選ぶことができるため，テンポによって生まれる音楽表現について，楽曲の創造の幅を広げることが可能となっている．</div></section><section class="max-width-4 mx-auto px2"><h2 class="px2 pb1 border-bottom">Information</h2><div class="px2 clearfix"><div class="col col-12 mb1"><div class="bold">Book title</div><div>研究報告ヒューマンコンピュータインタラクション（HCI）</div></div><div class="col col-12 md-col-6 mb1"><div class="clearfix"><div class="left col col-4 bold">Volume</div><div class="right col col-8">2014-HCI-157</div></div></div><div class="col col-12 md-col-6 mb1"><div class="clearfix"><div class="left col col-4 bold">Issue</div><div class="right col col-8">17</div></div></div><div class="col col-12 md-col-6 mb1"><div class="clearfix"><div class="left col col-4 bold">Pages</div><div class="right col col-8">1-8</div></div></div><div class="col col-12 md-col-6 mb1"><div class="clearfix"><div class="left col col-4 bold">Date of issue</div><div class="right col col-8"><date>2014/03/06</date></div></div></div></div></section><section class="max-width-4 mx-auto px2"><h2 class="px2 pb1 border-bottom">Articles</h2><ul class="p0 px2 link-list"><li class="inline-block mr2 pb1"><i class="mr1 fa fa-lg fa-file-pdf-o"></i><a href="https://research.miyashita.com/2014/D139/D139.pdf">Paper (PDF)</a></li><li class="inline-block mr2 pb1"><i class="mr1 fa fa-lg fa-file-text-o"></i><a href="bibtex.bib">BibTeX</a></li><li class="inline-block mr2 pb1"><i class="mr1 fa fa-lg fa-file-code-o"></i><a href="csl.json">CSL-JSON</a></li></ul></section><section class="max-width-4 mx-auto px2"><p class="px2 pb1 border-bottom right-align"><small><span class="bold">Source URL</span><wbr><a class="pl1" href="http://id.nii.ac.jp/1001/00099194/">http://id.nii.ac.jp/1001/00099194/</a></small></p></section><footer class="max-width-4 mx-auto px2 my3"><div class="center"><small>&copy; 情報処理学会, 2014</small></div><div class="center notice"><small>By using this site, you agree to the <a href="/copyright">Copyright Notice</a>.</small></div></footer></body></html>